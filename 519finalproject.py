# -*- coding: utf-8 -*-
"""519FinalProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZQMHdg_lXRhiHbKhGmSxdyhz_rylmObg

# Get Data
"""

############################# Import Statements ##############################

#fileio imports
from io import BytesIO
import urllib.request
import tarfile
import nltk

#basic imports
import operator
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

#preprocessing imports
from nltk.tokenize.toktok import ToktokTokenizer
from nltk.corpus import stopwords
from bs4 import BeautifulSoup
import os,re,string
from nltk.stem.porter import PorterStemmer
from wordcloud import WordCloud,STOPWORDS

#model imports 
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score, f1_score

from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from keras import initializers, regularizers, constraints, optimizers, layers
from keras.preprocessing.sequence import pad_sequences
from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten, Bidirectional, GlobalMaxPool1D,  Convolution1D
from keras.models import Model, Sequential

#interactive imports
import requests
from bs4 import BeautifulSoup
import itertools
import this

#the file is huge so this takes a little bit of time to get all the data 
#we read in the zipped file using ftpstream and bytesio 
tarfile_url = "https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"
ftpstream = urllib.request.urlopen(tarfile_url)

tmpfile = BytesIO()
while True:
    s = ftpstream.read(16384)
    if not s: break
    tmpfile.write(s)
ftpstream.close()

#we seek to the root of the file we just got 
tmpfile.seek(0)

tfile = tarfile.open(fileobj=tmpfile, mode="r:gz")

#we find all the files that have pos or neg in their path (these are the text files we want)
pos_review_filenames = [filename for filename in tfile.getnames() if "/pos/" in filename]
neg_review_filenames = [filename for filename in tfile.getnames() if "/neg/" in filename]

#now we simply read in the text from each file and append it into our arrays
pos = []
for filename in pos_review_filenames:
    review_stream = tfile.extractfile(filename)
    pos.append(review_stream.read())
    
neg = []
for filename in neg_review_filenames:
    review_stream = tfile.extractfile(filename)
    neg.append(review_stream.read())

#don't forget to close the streams and readers!!
tfile.close()
tmpfile.close()

print("number of positive reviews" + str(len(pos)))
print("number of negative reviews" + str(len(neg)))

display(pos[1])
display(neg[1])

"""# Pre Processing


"""

pos = pos[0:5000]
neg = neg[0:5000]

random_state = 530
#split up the training and test sets for both positive and negative reviews 

#this is the labels of all the positive reviews 
sentiment_pos = [1]*len(pos)
#we split the positive dataset into reviews training and test
review_p_train, review_p_test, sentiment_p_train, sentiment_p_test = train_test_split(pos, sentiment_pos, test_size=1000, random_state=random_state)

#this is the labels of all the negative reviews
sentiment_neg = [0]*len(neg)
#we split the negative dataset into reviews training and test
review_n_train, review_n_test, sentiment_n_train, sentiment_n_test = train_test_split(neg, sentiment_neg, test_size=1000, random_state=random_state)

#lets just make sure we are splitting as we want! 
print(len(review_p_train), len(review_p_test), len(sentiment_p_train), len(sentiment_p_test) )
print(len(review_n_train), len(review_n_test), len(sentiment_n_train), len(sentiment_n_test) )

#a bunch of basic preprocessing like removing noise, special characters
def denoise_text(text):
    #strips html away 
    text = BeautifulSoup(text, "html.parser")
    #removes square brackets 
    text = re.sub('\[[^]]*\]', '', str(text))
    #removes special characters
    pattern=r'[^a-zA-z0-9\s]'
    text = re.sub(pattern,'',str(text))
    return text

#Apply function to every review 
review_p_train = list(map(denoise_text, review_p_train))
review_n_train = list(map(denoise_text, review_n_train))
review_p_test = list(map(denoise_text, review_p_test))
review_n_test = list(map(denoise_text, review_n_test))

#Stemming the text
def stemmer(text):
    ps = nltk.porter.PorterStemmer()
    text= ' '.join([ps.stem(word) for word in text.split()])
    return text

#Apply function to every review 
review_p_train = list(map(stemmer, review_p_train))
review_n_train = list(map(stemmer, review_n_train))
review_p_test = list(map(stemmer, review_p_test))
review_n_test = list(map(stemmer, review_n_test))

nltk.download("stopwords")

#Tokenization of text
tokenizer = ToktokTokenizer()
#Get the stopwords in english
stopword_list = stopwords.words('english')

#set stopwords to english
stop = set(stopword_list)
#lets look at some of the stop words
print(stop)

#removing the stopwords
def remove_stopwords(text, is_lower_case=False):
    tokens = tokenizer.tokenize(text)
    tokens = [token.strip() for token in tokens]
    if is_lower_case:
        filtered_tokens = [token for token in tokens if token not in stopword_list]
    else:
        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]
    filtered_text = ' '.join(filtered_tokens)    
    return filtered_text

#Apply function to every review 
review_p_train = list(map(remove_stopwords, review_p_train))
review_n_train = list(map(remove_stopwords, review_n_train))
review_p_test = list(map(remove_stopwords, review_p_test))
review_n_test = list(map(remove_stopwords, review_n_test))

# pretty much done the preprocessing and cleaning lets check it out
# we can still do more removal 
print(review_p_train[1])
print(review_p_test[1])
print(review_n_train[1])
print(review_n_test[1])

plt.figure(figsize=(10,10))
pos_text = (" ").join(review_p_train)

wc = WordCloud(width=1000,height=500,max_words=500,min_font_size=5)
positive_words = wc.generate(pos_text)
plt.imshow(positive_words,interpolation='bilinear')
plt.show

plt.figure(figsize=(10,10))
pos_text = (" ").join(review_n_train)

wc = WordCloud(width=1000,height=500,max_words=500,min_font_size=5)
positive_words = wc.generate(pos_text)
plt.imshow(positive_words,interpolation='bilinear')
plt.show

"""# Models

Here we are going to use three types of representations. The first will be a sparse bag of word matrix representation, the second is an ngram based bag of words model, and the final is a term frequency document model. All three will be using a custom tokenize function that I have written in order to improve the accuracy of the CountVectorizer function.
"""

#custom tokenizer function
re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')
def tokenize(s): return re_tok.sub(r' \1 ', s).split()

#Count Vectorizer for sparse bag of words model 
sparse = CountVectorizer(tokenizer=tokenize)

#transformed train reviews 
sparse_train_reviews = sparse.fit_transform(review_p_train + review_n_train)

#transformed test reviews
sparse_test_reviews = sparse.transform(review_p_test + review_n_test)

print('len, sparse features:', sparse_train_reviews.shape)
print('len, sparse features:', sparse_test_reviews.shape)

#Count vectorizer for bag of words model using 7-grams
cv = CountVectorizer(ngram_range=(1,7), tokenizer=tokenize, max_features=53417)

#transformed train reviews
cv_train_reviews = cv.fit_transform(review_p_train + review_n_train)

#transformed test reviews
cv_test_reviews = cv.transform(review_p_test + review_n_test)

print('len, BOW features:', cv_train_reviews.shape)
print('len, BOW features:', cv_test_reviews.shape)

#Let us now create a term frequency document instead of BOW 
tf=TfidfVectorizer(use_idf=True,ngram_range=(1,7), tokenizer=tokenize,  max_features=53417)

#transformed train reviews
tf_train_reviews = tf.fit_transform(review_p_train + review_n_train)

#transformed test reviews
tf_test_reviews = tf.transform(review_p_test + review_n_test)

print('len, tfidf features:', tf_train_reviews.shape)
print('len, tfidf features:', tf_test_reviews.shape)

"""## Logistic Regression

"""

# hyperparamter tuning for logistic regression 
from sklearn.model_selection import GridSearchCV

model = LogisticRegression()
solvers = ['newton-cg', 'lbfgs', 'liblinear']
penalty = ['l2']
c_values = [100, 10, 1.0, 0.1, 0.01]

# Here we start the grid search 
grid = dict(solver=solvers,penalty=penalty,C=c_values)
grid_search_1 = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_2 = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_3 = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)

grid_result_1 = grid_search_1.fit(sparse_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best Sparse: %f using %s" % (grid_result_1.best_score_, grid_result_1.best_params_))
grid_result_2 = grid_search_2.fit(cv_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best BOW ngram: %f using %s" % (grid_result_2.best_score_, grid_result_2.best_params_))
grid_result_3 = grid_search_3.fit(tf_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best tfidf: %f using %s" % (grid_result_3.best_score_, grid_result_3.best_params_))

#training the logistic regression model 
lr_1 = LogisticRegression(C=0.1,random_state=31,solver='newton-cg')
lr_2 = LogisticRegression(C=0.1,random_state=31,solver='liblinear')
lr_3 = LogisticRegression(C=0.1,random_state=31,solver='newton-cg')

#Fitting the model for sparse BOW 
lr_sparse = lr_1.fit(sparse_train_reviews, sentiment_p_train + sentiment_n_train)
print(lr_sparse)

#Fitting the model for BOW
lr_bow = lr_2.fit(cv_train_reviews, sentiment_p_train + sentiment_n_train)
print(lr_bow)

#Fitting the model for tfidf features
lr_tfidf = lr_3.fit(tf_train_reviews,sentiment_p_train+sentiment_n_train)
print(lr_tfidf)

#Predicting the logistitc regression model for sparse bag of words
lr_sparse_predict = lr_sparse.predict(sparse_test_reviews)
print(lr_sparse_predict)

#Predicting the logistic regression model for bag of words
lr_bow_predict = lr_bow.predict(cv_test_reviews)
print(lr_bow_predict)

##Predicting the logistic regression model for tfidf features
lr_tfidf_predict = lr_tfidf.predict(tf_test_reviews)
print(lr_tfidf_predict)

# lets gets some reports on how we did 

#Accuracy score for sparse bag of words
lr_sparse_score=accuracy_score(sentiment_p_test + sentiment_n_test,lr_sparse_predict)
print("Logistic Regression with BOW accuracy: ",lr_sparse_score)

#Classification report for sparse bag of words 
lr_sparse_report=classification_report(sentiment_p_test + sentiment_n_test, lr_sparse_predict,target_names=['Positive','Negative'])
print(lr_sparse_report)

#Accuracy score for bag of words
lr_bow_score=accuracy_score(sentiment_p_test + sentiment_n_test,lr_bow_predict)
print("Logistic Regression with BOW accuracy: ",lr_bow_score)

#Classification report for bag of words 
lr_bow_report=classification_report(sentiment_p_test + sentiment_n_test, lr_bow_predict,target_names=['Positive','Negative'])
print(lr_bow_report)

#Accuracy score for tfidf features
lr_tfidf_score=accuracy_score(sentiment_p_test + sentiment_n_test,lr_tfidf_predict)
print("Logisitic Regression with TFIDF accuracy: ",lr_tfidf_score)

#Classification report for tfidf features
lr_tfidf_report=classification_report(sentiment_p_test + sentiment_n_test,lr_tfidf_predict,target_names=['Positive','Negative'])
print(lr_tfidf_report)

#confusion matrix for sparse bag of words
cm_sparse=confusion_matrix(sentiment_p_test + sentiment_n_test,lr_sparse_predict,labels=[1,0])

matrix_sparse = pd.DataFrame(cm_sparse, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_sparse, annot=True)

#confusion matrix for bag of words
cm_bow=confusion_matrix(sentiment_p_test + sentiment_n_test,lr_bow_predict,labels=[1,0])

matrix_bow = pd.DataFrame(cm_bow, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_bow, annot=True)

#confusion matrix for tfidf features
cm_tfidf=confusion_matrix(sentiment_p_test + sentiment_n_test,lr_tfidf_predict,labels=[1,0])

matrix_tfidf = pd.DataFrame(cm_tfidf, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_tfidf, annot=True)

"""## Support Vector Machine with Stochastic Gradient Descent"""

# hyperparameter tuning for SVM 
svm = SGDClassifier()
alpha = [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]
max_iter = [500] 
loss = ['hinge']
grid = dict(alpha=alpha,max_iter=max_iter,loss=loss)
# Here we start the grid search 
grid_search_1 = GridSearchCV(estimator=svm, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_2 = GridSearchCV(estimator=svm, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_3 = GridSearchCV(estimator=svm, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)

grid_result_1 = grid_search_1.fit(sparse_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best Sparse: %f using %s" % (grid_result_1.best_score_, grid_result_1.best_params_))
grid_result_2 = grid_search_2.fit(cv_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best BOW ngram: %f using %s" % (grid_result_2.best_score_, grid_result_2.best_params_))
grid_result_3 = grid_search_3.fit(tf_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best tfidf: %f using %s" % (grid_result_3.best_score_, grid_result_3.best_params_))

#training the linear svm
svm_1 = SGDClassifier(loss='hinge',max_iter=500,random_state=42, alpha=0.01)
svm_2 = SGDClassifier(loss='hinge',max_iter=500,random_state=42, alpha=0.01)
svm_3 = SGDClassifier(loss='hinge',max_iter=500,random_state=42, alpha=0.01)

#fitting the svm for sparse bag of words
svm_sparse=svm_1.fit(sparse_train_reviews,sentiment_p_train+sentiment_n_train)
print(svm_sparse)

#fitting the svm for bag of words
svm_bow=svm_2.fit(cv_train_reviews,sentiment_p_train+sentiment_n_train)
print(svm_bow)

#fitting the svm for tfidf features
svm_tfidf=svm_1.fit(tf_train_reviews,sentiment_p_train+sentiment_n_train)
print(svm_tfidf)

#Predicting the model for sprase bag of words
svm_sparse_predict=svm_sparse.predict(sparse_test_reviews)

#Predicting the model for bag of words
svm_bow_predict=svm_bow.predict(cv_test_reviews)

#Predicting the model for tfidf features
svm_tfidf_predict=svm_tfidf.predict(tf_test_reviews)

# lets gets some reports on how we did 

#Accuracy score for sparse bag of words
svm_sparse_score=accuracy_score(sentiment_p_test + sentiment_n_test,svm_sparse_predict)
print("SVM with sprase BOW accuracy: ",svm_sparse_score)

#Classification report for sparse bag of words 
svm_sparse_report=classification_report(sentiment_p_test + sentiment_n_test, svm_sparse_predict,target_names=['Positive','Negative'])
print(svm_sparse_report)

#Accuracy score for bag of words
svm_bow_score=accuracy_score(sentiment_p_test + sentiment_n_test,svm_bow_predict)
print("SVM with BOW accuracy: ",svm_bow_score)

#Classification report for bag of words 
svm_bow_report=classification_report(sentiment_p_test + sentiment_n_test, svm_bow_predict,target_names=['Positive','Negative'])
print(svm_bow_report)

#Accuracy score for tfidf features
svm_tfidf_score=accuracy_score(sentiment_p_test + sentiment_n_test,svm_tfidf_predict)
print("SVM with TFIDF accuracy: ",svm_tfidf_score)

#Classification report for tfidf features
svm_tfidf_report=classification_report(sentiment_p_test + sentiment_n_test,svm_tfidf_predict,target_names=['Positive','Negative'])
print(svm_tfidf_report)

#confusion matrix for sparse bag of words
cm_sparse=confusion_matrix(sentiment_p_test + sentiment_n_test,svm_sparse_predict,labels=[1,0])

matrix_sparse = pd.DataFrame(cm_sparse, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_sparse, annot=True)

#confusion matrix for bag of words
cm_bow=confusion_matrix(sentiment_p_test + sentiment_n_test,svm_bow_predict,labels=[1,0])

matrix_bow = pd.DataFrame(cm_bow, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_bow, annot=True)

#confusion matrix for tfidf features
cm_tfidf=confusion_matrix(sentiment_p_test + sentiment_n_test,svm_tfidf_predict,labels=[1,0])

matrix_tfidf = pd.DataFrame(cm_tfidf, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_tfidf, annot=True)

"""## Naives Bayes"""

# hyperparameter tuning for Naives Bayes
nb = MultinomialNB()
alpha = [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]
grid = dict(alpha=alpha)
# Here we start the grid search 
grid_search_1 = GridSearchCV(estimator=nb, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_2 = GridSearchCV(estimator=nb, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_3 = GridSearchCV(estimator=nb, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)

grid_result_1 = grid_search_1.fit(sparse_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best Sparse: %f using %s" % (grid_result_1.best_score_, grid_result_1.best_params_))
grid_result_2 = grid_search_2.fit(cv_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best BOW ngram: %f using %s" % (grid_result_2.best_score_, grid_result_2.best_params_))
grid_result_3 = grid_search_3.fit(tf_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best tfidf: %f using %s" % (grid_result_3.best_score_, grid_result_3.best_params_))

#training the Naives Bayes Model
nbm_1 = MultinomialNB(alpha=1)
nbm_2 = MultinomialNB(alpha=0.1)
nbm_3 = MultinomialNB(alpha=0.1)

#fitting the NBM for sparse bag of words
nbm_sparse = nbm_1.fit(sparse_train_reviews,sentiment_p_train+sentiment_n_train)
print(nbm_sparse)

#fitting the NBM for bag of words
nbm_bow = nbm_2.fit(cv_train_reviews,sentiment_p_train+sentiment_n_train)
print(nbm_bow)

#fitting the NBM for tfidf features
nbm_tfidf = nbm_3.fit(tf_train_reviews,sentiment_p_train+sentiment_n_train)
print(nbm_tfidf)

#Predicting the model for bag of words
nbm_sparse_predict=nbm_sparse.predict(sparse_test_reviews)

#Predicting the model for bag of words
nbm_bow_predict=nbm_bow.predict(cv_test_reviews)

#Predicting the model for tfidf features
nbm_tfidf_predict=nbm_tfidf.predict(tf_test_reviews)

# lets gets some reports on how we did 

#Accuracy score for bag of words
nbm_sparse_score=accuracy_score(sentiment_p_test + sentiment_n_test,nbm_sparse_predict)
print("Naives Bayes with sparse BOW accuracy: ",nbm_sparse_score)

#Classification report for bag of words 
nbm_sparse_report=classification_report(sentiment_p_test + sentiment_n_test, nbm_sparse_predict,target_names=['Positive','Negative'])
print(nbm_sparse_report)

#Accuracy score for bag of words
nbm_bow_score=accuracy_score(sentiment_p_test + sentiment_n_test,nbm_bow_predict)
print("Naives Bayes with BOW accuracy: ",nbm_bow_score)

#Classification report for bag of words 
nbm_bow_report=classification_report(sentiment_p_test + sentiment_n_test, nbm_bow_predict,target_names=['Positive','Negative'])
print(nbm_bow_report)

#Accuracy score for tfidf features
nbm_tfidf_score=accuracy_score(sentiment_p_test + sentiment_n_test,nbm_tfidf_predict)
print("Naives Bayes with TFIDF accuracy: ",nbm_tfidf_score)

#Classification report for tfidf features
nbm_tfidf_report=classification_report(sentiment_p_test + sentiment_n_test,nbm_tfidf_predict,target_names=['Positive','Negative'])
print(nbm_tfidf_report)

#confusion matrix for sparse bag of words
cm_sparse = confusion_matrix(sentiment_p_test + sentiment_n_test,nbm_sparse_predict,labels=[1,0])

matrix_sparse = pd.DataFrame(cm_sparse, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_sparse, annot=True)

#confusion matrix for bag of words
cm_bow=confusion_matrix(sentiment_p_test + sentiment_n_test,nbm_bow_predict,labels=[1,0])

matrix_bow = pd.DataFrame(cm_bow, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_bow, annot=True)

#confusion matrix for tfidf features
cm_tfidf=confusion_matrix(sentiment_p_test + sentiment_n_test,nbm_tfidf_predict,labels=[1,0])

matrix_tfidf = pd.DataFrame(cm_tfidf, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_tfidf, annot=True)

"""## Random Forest Classifier"""

# hyperparameter tuning for Random Forest
rf = RandomForestClassifier()
n_estimators = [10, 100, 250]
max_features = [1, 5, 10, 25, 50]
# Here we start the grid search
grid = dict(n_estimators=n_estimators,max_features=max_features) 
grid_search_1 = GridSearchCV(estimator=rf, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_2 = GridSearchCV(estimator=rf, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)
grid_search_3 = GridSearchCV(estimator=rf, param_grid=grid, n_jobs=-1, scoring='accuracy',error_score=0)

# Print Results
grid_result_1 = grid_search_1.fit(sparse_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best Sparse: %f using %s" % (grid_result_1.best_score_, grid_result_1.best_params_))
grid_result_2 = grid_search_2.fit(cv_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best BOW ngram: %f using %s" % (grid_result_2.best_score_, grid_result_2.best_params_))
grid_result_3 = grid_search_3.fit(tf_train_reviews, sentiment_p_train + sentiment_n_train)
print("Best tfidf: %f using %s" % (grid_result_3.best_score_, grid_result_3.best_params_))

#training the Random Forest Model
rf_1 = RandomForestClassifier(n_estimators = 100, max_depth=50)
rf_2 = RandomForestClassifier(n_estimators = 100, max_depth=50)
rf_3 = RandomForestClassifier(n_estimators = 100, max_depth=50)


#fitting the random forest for sparse bag of words
rf_sparse = rf_1.fit(sparse_train_reviews,sentiment_p_train+sentiment_n_train)
print(rf_sparse)

#fitting the random forest for bag of words
rf_bow = rf_2.fit(cv_train_reviews,sentiment_p_train+sentiment_n_train)
print(rf_bow)

#fitting the random forest for tfidf features
rf_tfidf = rf_3.fit(tf_train_reviews,sentiment_p_train+sentiment_n_train)
print(rf_tfidf)

#Predicting the model for bag of words
rf_sparse_predict=  rf_sparse.predict(cv_test_reviews)

#Predicting the model for bag of words
rf_bow_predict=  rf_bow.predict(cv_test_reviews)

#Predicting the model for tfidf features
rf_tfidf_predict = rf_tfidf.predict(tf_test_reviews)

# lets gets some reports on how we did 

#Accuracy score for sparse bag of words
rf_sparse_score=accuracy_score(sentiment_p_test + sentiment_n_test,rf_sparse_predict)
print("Naives Bayes with BOW accuracy: ",rf_sparse_score)

#Classification report for sparse bag of words 
rf_sparse_report=classification_report(sentiment_p_test + sentiment_n_test, rf_sparse_predict,target_names=['Positive','Negative'])
print(rf_sparse_report)


#Accuracy score for bag of words
rf_bow_score=accuracy_score(sentiment_p_test + sentiment_n_test,rf_bow_predict)
print("Naives Bayes with BOW accuracy: ",rf_bow_score)

#Classification report for bag of words 
rf_bow_report=classification_report(sentiment_p_test + sentiment_n_test, rf_bow_predict,target_names=['Positive','Negative'])
print(rf_bow_report)

#Accuracy score for tfidf features
rf_tfidf_score=accuracy_score(sentiment_p_test + sentiment_n_test,rf_tfidf_predict)
print("Naives Bayes with TFIDF accuracy: ",rf_tfidf_score)

#Classification report for tfidf features
rf_tfidf_report=classification_report(sentiment_p_test + sentiment_n_test,rf_tfidf_predict,target_names=['Positive','Negative'])
print(rf_tfidf_report)

#confusion matrix for sparse bag of words
cm_sparse=confusion_matrix(sentiment_p_test + sentiment_n_test,rf_sparse_predict,labels=[1,0])

matrix_sparse = pd.DataFrame(cm_sparse, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_sparse, annot=True)

#confusion matrix for bag of words
cm_bow=confusion_matrix(sentiment_p_test + sentiment_n_test,rf_bow_predict,labels=[1,0])

matrix_bow = pd.DataFrame(cm_bow, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_bow, annot=True)

#confusion matrix for bag of words
cm_bow=confusion_matrix(sentiment_p_test + sentiment_n_test,rf_tfidf_predict,labels=[1,0])

matrix_bow = pd.DataFrame(cm_bow, index = [i for i in "01"],
                  columns = [i for i in "01"])
plt.figure(figsize = (10,7))
sns.heatmap(matrix_bow, annot=True)

"""## Nueral Net

"""

from keras.preprocessing.text import Tokenizer

# Here we must turn our reviews into tokens for our model to run 
max_features = 600000
tokenizer = Tokenizer(num_words=max_features)
tokenizer.fit_on_texts(review_p_train + review_n_train)
list_tokenized_train = tokenizer.texts_to_sequences(review_p_train + review_n_train)

# here we pad the tokens to ensure that the reviewis all are the same length in order to pass it into the nueral net
maxlen = 100
x = pad_sequences(list_tokenized_train, maxlen=maxlen)
y = np.array(sentiment_p_train + sentiment_n_train)

# just do the same for test reviews 
y_test = np.array(sentiment_p_test + sentiment_n_test)
list_tokenized_test = tokenizer.texts_to_sequences(review_p_test + review_n_test)
x_test = pad_sequences(list_tokenized_test, maxlen=maxlen)

# define the nueral net
embed_size =  256
model = Sequential()
model.add(Embedding(max_features, embed_size))
model.add(Bidirectional(LSTM(32, return_sequences = True)))
model.add(GlobalMaxPool1D())
model.add(Dense(20, activation="relu"))
model.add(Dropout(0.03))
model.add(Dense(1, activation="sigmoid"))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# actually training the NN
model.fit(x,y, batch_size=100, epochs=3, validation_split=0.2)

# testing our model 
prediction = model.predict(x_test)
y_pred = (prediction > 0.5)
print('F1 score: {0}'.format(f1_score(y_pred, y_test)))
confusion_matrix(y_pred, y_test)

"""## Let's Have Some Fun

"""

import requests
from bs4 import BeautifulSoup

def getSoup(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    return soup

def getRating(movie):
  query = movie.replace(" ", "+")

  url = 'https://www.imdb.com/search/title/?title=' + query

  # get the soup object for main api url
  movies_soup = getSoup(url)
  # find all a-tags with class:None
  movie_tags = movies_soup.find_all('a', attrs={'class': None})

  # filter the a-tags to get just the titles
  movie_tags = [tag.attrs['href'] for tag in movie_tags 
                if tag.attrs['href'].startswith('/title') & tag.attrs['href'].endswith('/')]

  # remove duplicate links
  movie_tags = list(dict.fromkeys(movie_tags))

  movie_tags[0]
  # print(movie_tags[0])

  # movie links
  base_url = "https://www.imdb.com"
  movie_link = base_url + movie_tags[0] + 'reviews'
  movie_soup = getSoup(movie_link)

  movie_review_tags = movie_soup.find_all('a', attrs={'class':'title'})
  movie_reviews = []
  for tag in movie_review_tags: 
    link = "https://www.imdb.com" + tag['href']
    review_soup = getSoup(link)
    tag = review_soup.find('div', attrs={'class': 'text show-more__control'})
    movie_reviews.append(tag.getText())

  movie_reviews

  reviews = list(map(denoise_text, movie_reviews))
  reviews = list(map(stemmer, reviews))
  reviews = list(map(remove_stopwords, reviews))

  vectorized_reviews = tf.transform(reviews)
  predictions=nbm_tfidf.predict(vectorized_reviews)
  preds = np.array(predictions)
  accuracy = (np.count_nonzero(preds==1))/len(predictions)
  accuracy
  return accuracy

def runInteractive():
  tries = 0
  while tries < 4:
    movie = input("What movie do you want to know the rating for?: \t")
    try:
      rating = getRating(movie)
      print(movie+ " has a rating of: " + str(round(rating*10,2)) + "/10")
    except:
      print("Sorry the movie could not be found. Please try again or try another movie.")
    tries += 1
  print("Hope you enjoyed this!")

runInteractive()